{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "# Training and Deploying a Prediction model for Real-time Inference\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. Use Python & SQL to query the public data in BigQuery.\n",
    "2. Prepare the data for modeling.\n",
    "3. Train a classification model using BigQuery ML.\n",
    "4. Inspect the model on Vertex AI Model Registry.\n",
    "5. Deploy the model to an endpoint.\n",
    "6. Make online predictions to the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook is used to train a model using BigQuery ML, register the model to Vertex AI Model Registry, and deploy it to an endpoint for real-time prediction. \n",
    "\n",
    "It includes the steps to train and deploy a churn prediction model for real-time inference, with the data in BigQuery and model trained using BigQuery ML, registered to Vertex AI Model Registry, and deployed to an endpoint on Vertex AI for online predictions.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset, comes from BQ public dataset <a href=\"https://support.google.com/analytics/answer/10937659\" target=\"_blank\">Google Analytics 4 data</a> from the <a href=\"https://shop.googlemerchandisestore.com/\" target=\"_blank\">Google Merchandise Store</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### Install additional packages\n",
    "\n",
    "Install the following packages required to execute this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b4ef9b72d43"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Vertex AI Workbench Notebook product has specific requirements\n",
    "IS_WORKBENCH_NOTEBOOK = os.getenv(\"DL_ANACONDA_HOME\")\n",
    "IS_USER_MANAGED_WORKBENCH_NOTEBOOK = os.path.exists(\n",
    "    \"/opt/deeplearning/metadata/env_version\"\n",
    ")\n",
    "\n",
    "# Vertex AI Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_WORKBENCH_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\"\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform {USER_FLAG} -q google-cloud-bigquery db-dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhq5zEbGg0XX"
   },
   "source": [
    "### Restart the kernel\n",
    "\n",
    "After you install the additional packages, you need to restart the notebook kernel so it can find the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EzrelQZ22IZj"
   },
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "### Set the project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"[your-project-id]\" # Replace with your Project ID\n",
    "\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID: \", PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "region"
   },
   "source": [
    "#### Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"[your-region]\"  # Replace with your region\n",
    "\n",
    "if REGION == \"[your-region]\":\n",
    "    REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06571eb4063b"
   },
   "source": [
    "#### UUID\n",
    "\n",
    "Since you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a uuid for each instance session, and append it onto the name of resources you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "697568e92bd6"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "\n",
    "# Generate a uuid of a specifed length(default=8)\n",
    "def generate_uuid(length: int = 8) -> str:\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "UUID = generate_uuid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRUOFELefqf1"
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import google.cloud.aiplatform as vertex_ai\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "source": [
    "### Initialize Vertex AI and BigQuery SDKs for Python\n",
    "\n",
    "Initialize the Vertex AI SDK for Python for your project and corresponding bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "outputs": [],
   "source": [
    "vertex_ai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83859376c893"
   },
   "source": [
    "Create the BigQuery client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0ab485806b17"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bigquery' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the BigQuery client w.r.t your Project ID\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m bq_client \u001b[38;5;241m=\u001b[39m \u001b[43mbigquery\u001b[49m\u001b[38;5;241m.\u001b[39mClient(project\u001b[38;5;241m=\u001b[39mPROJECT_ID)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bigquery' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the BigQuery client w.r.t your Project ID\n",
    "bq_client = bigquery.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f94734ac9312"
   },
   "source": [
    "Use a helper function for sending queries to BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e364dab1d353"
   },
   "outputs": [],
   "source": [
    "# Wrapper to use BigQuery client to run query/job, return job ID or result as DF\n",
    "def run_bq_query(sql: str) -> Union[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Input: SQL query, as a string, to execute in BigQuery\n",
    "    Returns the query results as a pandas DataFrame, or error, if any\n",
    "    \"\"\"\n",
    "\n",
    "    # Try dry run before executing query to catch any errors\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    # If dry run succeeds without errors, proceed to run query\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    client_result = bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    job_id = client_result.job_id\n",
    "\n",
    "    # Wait for query/job to finish running. then get & return data frame\n",
    "    df = client_result.result().to_arrow().to_pandas()\n",
    "    print(f\"Finished job_id: {job_id}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4a686de97f5"
   },
   "source": [
    "## BigQuery ML introduction\n",
    "\n",
    "BigQuery ML (BQML) provides the capability to train ML tabular models, such as classification, regression, forecasting, and matrix factorization, in BigQuery using SQL syntax directly. BigQuery ML uses the scalable infrastructure of BigQuery ML so you don't need to set up additional infrastructure for training or batch serving.\n",
    "\n",
    "Learn more about <a href=\"https://cloud.google.com/bigquery-ml/docs\" target=\"_blank\">BigQuery ML documentation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "088e3b9577b3"
   },
   "outputs": [],
   "source": [
    "BQ_DATASET_NAME = f\"ga4_churnprediction_{UUID}\"\n",
    "\n",
    "sql_create_dataset = f\"\"\"CREATE SCHEMA IF NOT EXISTS {BQ_DATASET_NAME}\"\"\"\n",
    "\n",
    "print(sql_create_dataset)\n",
    "\n",
    "run_bq_query(sql_create_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13b6ce9f8d8b"
   },
   "source": [
    "### Inspect the pre-processed Google Analytics 4 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49dd00d5fbe5"
   },
   "source": [
    "Inpect data that has been pre-processed from <a href=\"https://support.google.com/analytics/answer/10937659\" target=\"_blank\">Google Analytics 4 data from the Google Merchandise Store</a> so that it can be used for classification. For more information on how this data was prepared, read <a href=\"https://cloud.google.com/blog/topics/developers-practitioners/churn-prediction-game-developers-using-google-analytics-4-ga4-and-bigquery-ml\" target=\"_blank\">this blog post</a>.\n",
    "\n",
    "As seen below, each row represents a single user, and the columns represent their demographic features, their aggregated behavioral features in the first 24 hours of visiting the Google Merchandise Store, and the label (whether the user churned or returned any time after the first 24 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0916b03610bd"
   },
   "outputs": [],
   "source": [
    "sql_inspect = \"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    `bqmlpublic.demo_ga4churnprediction.training_data`\n",
    "LIMIT\n",
    "    100\n",
    "\"\"\"\n",
    "run_bq_query(sql_inspect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02f304053600"
   },
   "source": [
    "### Train a classification model using BigQuery ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "566f3395f20b"
   },
   "source": [
    "The query below trains a logistic regression model using BigQuery ML. BigQuery resources are used to train the model.\n",
    "\n",
    "In the `OPTIONS` parameter:\n",
    "* with `model_registry=\"vertex_ai\"`, the BigQuery ML model will automatically be <a href=\"https://cloud.google.com/vertex-ai/docs/model-registry/model-registry-bqml\" target=\"_blank\">registered to Vertex AI Model Registry</a>, which enables you to view all of your registered models and its versions on Google Cloud in one place.\n",
    "\n",
    "* `vertex_ai_model_version_aliases allows you to set aliases to help you keep track of your model version (<a href=\"https://cloud.google.com/vertex-ai/docs/model-registry/model-alias\" target=\"_blank\">documentation</a>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "414c45011c1f"
   },
   "outputs": [],
   "source": [
    "# TODO 2\n",
    "# this cell may take ~1 min to run\n",
    "# Create a classification model\n",
    "\n",
    "BQML_MODEL_NAME = f\"bqml_model_churn_{UUID}\"\n",
    "\n",
    "sql_train_model_bqml = f\"\"\"\n",
    "CREATE OR REPLACE MODEL {BQ_DATASET_NAME}.{BQML_MODEL_NAME}    \n",
    "OPTIONS(\n",
    "  MODEL_TYPE=\"LOGISTIC_REG\",\n",
    "  input_label_cols=[\"churned\"],\n",
    "  model_registry=\"vertex_ai\",\n",
    "  vertex_ai_model_version_aliases=['logistic_reg', 'experimental']\n",
    ") AS\n",
    "\n",
    "SELECT\n",
    "  * EXCEPT(user_first_engagement, user_pseudo_id)\n",
    "FROM\n",
    "  bqmlpublic.demo_ga4churnprediction.training_data\n",
    "\"\"\"\n",
    "\n",
    "print(sql_train_model_bqml)\n",
    "\n",
    "run_bq_query(sql_train_model_bqml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a90e98c72a05"
   },
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aaaae772f67"
   },
   "source": [
    "With the model created, you can now evaluate the logistic regression model. Behind the scenes, BigQuery ML automatically <a href=\"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create#data_split_method\" target=\"_blank\">split the data</a>, which makes it easier to quickly train and evaluate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1f8ac93d570"
   },
   "outputs": [],
   "source": [
    "sql_evaluate_model = f\"\"\"\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL {BQ_DATASET_NAME}.{BQML_MODEL_NAME})\n",
    "\"\"\"\n",
    "\n",
    "print(sql_evaluate_model)\n",
    "\n",
    "run_bq_query(sql_evaluate_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9f807a50f38"
   },
   "source": [
    "These metrics help you understand the performance of the model. \n",
    "\n",
    "There are various metrics for logistic regression and other model types (full list of metrics can be found in the <a href=\"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate#mlevaluate_output\" target=\"_blank\">documentation</a>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e806ebc48a2"
   },
   "source": [
    "### Batch prediction (with Explainable AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d31605829283"
   },
   "source": [
    "Make a batch prediction in BigQuery ML on the original training data to check the probability of churn for each of the users, as seen in the `probability` column, with the predicted label under the `predicted_churn` column.\n",
    "\n",
    "<a href=\"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-explain-predict\" target=\"_blank\">ML.EXPLAIN_PREDICT</a> has built-in <a href=\"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-xai-overview\" target=\"_blank\">Explainable AI</a>. This allows you to see the top contributing features to each prediction and interpret how it was computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2d500fdbfb44"
   },
   "outputs": [],
   "source": [
    "sql_explain_predict = f\"\"\"\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.EXPLAIN_PREDICT(MODEL {BQ_DATASET_NAME}.{BQML_MODEL_NAME},\n",
    "    (SELECT * FROM bqmlpublic.demo_ga4churnprediction.training_data LIMIT 100)\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "print(sql_explain_predict)\n",
    "\n",
    "run_bq_query(sql_explain_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa1f96c0f452"
   },
   "source": [
    "Since the `top_feature_attributions` is a nested column, you can unnest the array (<a href=\"https://cloud.google.com/bigquery/docs/reference/standard-sql/arrays\" target=\"_blank\">documentation</a>) into separate rows for each of the features. In other words, since ML.EXPLAIN_PREDICT provides the top 5 most important features, using `UNNEST` results in 5 rows per prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "278b3441084b"
   },
   "outputs": [],
   "source": [
    "sql_explain_predict = f\"\"\"\n",
    "SELECT\n",
    "  tfa.*,\n",
    "  predicted_churned,\n",
    "  probability,\n",
    "  baseline_prediction_value,\n",
    "  prediction_value,\n",
    "  approximation_error,\n",
    "  user_pseudo_id\n",
    "FROM\n",
    "  ML.EXPLAIN_PREDICT(MODEL {BQ_DATASET_NAME}.{BQML_MODEL_NAME},\n",
    "    (SELECT * FROM bqmlpublic.demo_ga4churnprediction.training_data LIMIT 100)\n",
    "    ),\n",
    "  UNNEST(top_feature_attributions) as tfa\n",
    "WHERE\n",
    "  user_pseudo_id = \"7666337.2408476627\"\n",
    "\"\"\"\n",
    "\n",
    "print(sql_explain_predict)\n",
    "\n",
    "run_bq_query(sql_explain_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc0c1c1b03f9"
   },
   "source": [
    "### Inspect the model on Vertex AI Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0144d67a298e"
   },
   "source": [
    "When the model was trained in BigQuery ML, the line `model_registry=\"vertex_ai\"` registered the model to Vertex AI Model Registry automatically upon completion.\n",
    "\n",
    "You can view the model on the <a href=\"https://console.cloud.google.com/vertex-ai/models\" target=\"_blank\">Vertex AI Model Registry page</a>:\n",
    "\n",
    "Or use the code below to check that it was successfully registered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "b00664302839"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vertex_ai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mvertex_ai\u001b[49m\u001b[38;5;241m.\u001b[39mModel(model_name\u001b[38;5;241m=\u001b[39mBQML_MODEL_NAME)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mgca_resource)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vertex_ai' is not defined"
     ]
    }
   ],
   "source": [
    "model = vertex_ai.Model(model_name=BQML_MODEL_NAME)\n",
    "\n",
    "print(model.gca_resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89455f708f54"
   },
   "source": [
    "### Deploy the model to an endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6120dcc1ff6"
   },
   "source": [
    "While BigQuery ML supports batch prediction with <a href=\"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict\" target=\"_blank\">ML.PREDICT</a> and <a href=\"https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-explain-predict\" target=\"_blank\">ML.EXPLAIN_PREDICT</a>, BigQuery ML is not suitable for real-time predictions where you need low latency predictions with potentially high frequency of requests.\n",
    "\n",
    "Deploying the BigQuery ML model to an endpoint enables you to do online predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1ab7e1ac83c"
   },
   "source": [
    "#### Create a Vertex AI endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a61ea55f685"
   },
   "source": [
    "To deploy your model to an endpoint, you first need to create an endpoint before you deploy the model to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7d80941cf30"
   },
   "outputs": [],
   "source": [
    "ENDPOINT_NAME = f\"{BQML_MODEL_NAME}-endpoint\"\n",
    "\n",
    "# Create a Vertex AI endpoint\n",
    "endpoint = vertex_ai.Endpoint.create(\n",
    "    display_name=ENDPOINT_NAME,\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    ")\n",
    "\n",
    "print(endpoint.display_name)\n",
    "print(endpoint.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b58a104207d2"
   },
   "source": [
    "#### List endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "951ed1693f6b"
   },
   "source": [
    "List the endpoints to make sure it has successfully been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4d7707910bc"
   },
   "outputs": [],
   "source": [
    "endpoint.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba0d40b26cfb"
   },
   "source": [
    "#### Deploy model to Vertex endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a90be5b77a2"
   },
   "source": [
    "With the new endpoint, you can now deploy your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c70ecc568ee5"
   },
   "outputs": [],
   "source": [
    "# Deploy your model to the endpoint (may take 10-15 minutes)\n",
    "model.deploy(endpoint=endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c303d779477b"
   },
   "source": [
    "You can also check on the status of your model by visiting the <a href=\"https://console.cloud.google.com/vertex-ai/endpoints\" target=\"_blank\">Vertex AI Endpoints page</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cb04d49c6f1"
   },
   "source": [
    "### Make online predictions to the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a888784de7b"
   },
   "source": [
    "Using a sample of the training data, you can test the endpoint to make online predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f17b049a846c"
   },
   "outputs": [],
   "source": [
    "df_sample_requests_list = [\n",
    "    {\n",
    "        \"country\": \"Turkey\",\n",
    "        \"operating_system\": \"Web\",\n",
    "        \"language\": \"None\",\n",
    "        \"cnt_user_engagement\": 28,\n",
    "        \"cnt_page_view\": 37,\n",
    "        \"cnt_view_item\": 6,\n",
    "        \"cnt_view_promotion\": 15,\n",
    "        \"cnt_select_promotion\": 4,\n",
    "        \"cnt_add_to_cart\": 0,\n",
    "        \"cnt_begin_checkout\": 0,\n",
    "        \"cnt_add_shipping_info\": 0,\n",
    "        \"cnt_add_payment_info\": 0,\n",
    "        \"cnt_purchase\": 0,\n",
    "        \"month\": 1,\n",
    "        \"julianday\": 1,\n",
    "        \"dayofweek\": 6,\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Macao\",\n",
    "        \"operating_system\": \"Web\",\n",
    "        \"language\": \"None\",\n",
    "        \"cnt_user_engagement\": 2,\n",
    "        \"cnt_page_view\": 4,\n",
    "        \"cnt_view_item\": 0,\n",
    "        \"cnt_view_promotion\": 0,\n",
    "        \"cnt_select_promotion\": 0,\n",
    "        \"cnt_add_to_cart\": 0,\n",
    "        \"cnt_begin_checkout\": 0,\n",
    "        \"cnt_add_shipping_info\": 0,\n",
    "        \"cnt_add_payment_info\": 0,\n",
    "        \"cnt_purchase\": 0,\n",
    "        \"month\": 1,\n",
    "        \"julianday\": 16,\n",
    "        \"dayofweek\": 7,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4839f31d2f8"
   },
   "outputs": [],
   "source": [
    "# Make the prediction to the endpoint\n",
    "prediction = endpoint.predict(df_sample_requests_list)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "347ffda86396"
   },
   "source": [
    "You can then extract the predictions from the prediction response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ea659b7c178d"
   },
   "outputs": [],
   "source": [
    "prediction.predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpV-iwP9qw9c"
   },
   "source": [
    "## Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sx_vKniMq9ZX"
   },
   "outputs": [],
   "source": [
    "# Undeploy model from endpoint and delete endpoint\n",
    "endpoint.undeploy_all()\n",
    "endpoint.delete()\n",
    "\n",
    "# Delete BigQuery dataset, including the BigQuery ML model\n",
    "! bq rm -r -f $PROJECT_ID:$BQ_DATASET_NAME"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bqml-online-prediction.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m95"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
